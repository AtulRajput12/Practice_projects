{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8cd0aa2",
   "metadata": {},
   "source": [
    "# Temperature Forecast Project using ML\n",
    "\n",
    "Problem Statement:\n",
    "\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "For more information, read [Cho et al, 2020].\n",
    "1. station - used weather station number: 1 to 25\n",
    "2. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')\n",
    "3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6\n",
    "4. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9\n",
    "5. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5\n",
    "6. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100\n",
    "7. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5\n",
    "8. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6\n",
    "9. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9\n",
    "10. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4\n",
    "11. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97\n",
    "12. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97\n",
    "13. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98\n",
    "14. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97\n",
    "15. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7\n",
    "16. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6\n",
    "17. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8\n",
    "18. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7\n",
    "19. lat - Latitude (Â°): 37.456 to 37.645\n",
    "20. lon - Longitude (Â°): 126.826 to 127.135\n",
    "21. DEM - Elevation (m): 12.4 to 212.3\n",
    "22. Slope - Slope (Â°): 0.1 to 5.2\n",
    "23. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9\n",
    "24. Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9\n",
    "25. Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8T\n",
    "\n",
    "Please note that there are two target variables here: \n",
    "\n",
    "1) Next_Tmax: Next day maximum temperature\n",
    "\n",
    "2) Next_Tmin: Next day  minimum temperature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/Dataset2/main/temperature.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12561a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f0410",
   "metadata": {},
   "source": [
    "now we have handle the nan value so lets proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6573b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unwanted columns\n",
    "data=data.drop([\"Date\"],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b278e",
   "metadata": {},
   "source": [
    "# first create model for next day maximum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into target and feature variable\n",
    "x=data.drop(['Next_Tmax','Next_Tmin'],axis=1)\n",
    "y=data[\"Next_Tmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa746c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524736f7",
   "metadata": {},
   "source": [
    "# check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71026405",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()\n",
    "corr_mat=data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of the canvas\n",
    "plt.figure(figsize=([20,20]))\n",
    "\n",
    "#plot the correlation matrix\n",
    "sns.heatmap(corr_mat,annot=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a62063",
   "metadata": {},
   "source": [
    "some columns are having high correlation so lets remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop([\"DEM\",\"LDAPS_CC4\",\"LDAPS_CC2\",\"LDAPS_Tmin_lapse\"],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25))\n",
    "plotnumber=1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=25:\n",
    "        ax=plt.subplot(5,5,plotnumber)\n",
    "        sns.distplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        \n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17409455",
   "metadata": {},
   "source": [
    "lets check for skewness in data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5cbe1",
   "metadata": {},
   "source": [
    "few columns are highly skeweed so lets remove the skewness using power_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4577a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "x_new=power_transform(x)\n",
    "x=pd.DataFrame(x_new,columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb526a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate that skewness is removed or not\n",
    "x.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93ca4c",
   "metadata": {},
   "source": [
    "most of the columns are well distributed so lets proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dc99a6",
   "metadata": {},
   "source": [
    "before we fit our data to a model . let's visualize the relationship between our independent variables and the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how features are related to class\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber=1\n",
    "\n",
    "for column in x:\n",
    "    if plotnumber<=25:\n",
    "        ax=plt.subplot(5,5,plotnumber)\n",
    "        sns.stripplot(y,x[column])\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d210a",
   "metadata": {},
   "source": [
    "greta let's proceed by checking multicollinearity in the dependent variables. before that we should scale our data. let's use standard scalar for that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b8e7d",
   "metadata": {},
   "source": [
    "# Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c722a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_scaled=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c637255",
   "metadata": {},
   "source": [
    "finding variance inflation factor in each scaled column i.e. x_scaled1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c104730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif=pd.DataFrame()\n",
    "vif[\"vif\"]=[variance_inflation_factor(x_scaled, i) for i in range(x_scaled.shape[1])]\n",
    "\n",
    "vif[\"Features\"]=x.columns\n",
    "\n",
    "#let's check the values\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453eb9f",
   "metadata": {},
   "source": [
    "some columns have high vif score we can drop those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['LDAPS_Tmax_lapse','LDAPS_RHmin'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0480c8",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998311a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "from sklearn.metrics import r2_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d638052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding  best random state\n",
    "maxAccu=0     #maximum accuracy\n",
    "maxRS=0       #best random state value for which max accuracy is achieved\n",
    "\n",
    "for i in range(1,100):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.25,random_state=i)\n",
    "    lr.fit(x_train,y_train)\n",
    "    pred=lr.predict(x_test)\n",
    "    acc=r2_score(y_test,pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print(\"Best Accuracy is :\",maxAccu,\"on Random_state\",maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cf502",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.25,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc150787",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4590a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajusted r2 score\n",
    "lr.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ab57b",
   "metadata": {},
   "source": [
    "lets check how well it fits the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73622c4",
   "metadata": {},
   "source": [
    "# cross validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bcc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy=lr.score(x_train,y_train)\n",
    "test_accuracy=lr.score(x_test,y_test)\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0560ca",
   "metadata": {},
   "source": [
    "# lets plot and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc677ca8",
   "metadata": {},
   "source": [
    "it shows the good fit of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6427207a",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters={'alpha':[.001,.001,.01,.1,1,10],'random_state':list(range(0,10))}\n",
    "ls=Lasso()\n",
    "clf=GridSearchCV(ls,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac073993",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=Lasso(alpha=1,random_state=0)\n",
    "ls.fit(x_train,y_train)\n",
    "ls_score_training=ls.score(x_train,y_train)\n",
    "pred_ls=ls.predict(x_test)\n",
    "ls_score_training*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "lss=r2_score(y_test,pred_ls)\n",
    "lss*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95033aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean*100\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67132533",
   "metadata": {},
   "source": [
    "# Ensemble technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd631185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "parameters={'criterion':['mse','mae'],'max_features':[\"auto\",\"sqrt\",\"log2\"]}\n",
    "rf=RandomForestRegressor()\n",
    "clf=GridSearchCV(rf,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(criterion=\"mse\",max_features=\"auto\")\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_train,y_train)\n",
    "pred_decision=rf.predict(x_test)\n",
    "\n",
    "rfs=r2_score(y_test,pred_decision)\n",
    "print('R2_score :',rfs*100)\n",
    "\n",
    "rfscore=cross_val_score(rf,x,y,cv=5)\n",
    "rfc=rfscore.mean()\n",
    "print('Cross_val_score :',rfc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9786589",
   "metadata": {},
   "source": [
    "we are getting good r2_score and cross_val_score which shows that model is performing well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a74955",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71866010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='Temperature Forecast.pkl'\n",
    "pickle.dump(rf,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194f9f3",
   "metadata": {},
   "source": [
    "# prediction using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413da983",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open('Temperature Forecast.pkl','rb'))\n",
    "result=loaded_model.score(x_test,y_test)\n",
    "print(result*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion=pd.DataFrame([loaded_model.predict(x_test)[:],pred_decision[:]],index=[\"Orignal\",\"Predicted\"])\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86744ea",
   "metadata": {},
   "source": [
    "# now create model for next day minimum temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5be5f",
   "metadata": {},
   "source": [
    "split the data in target and feature variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['Next_Tmax','Next_Tmin'],axis=1)\n",
    "y=data[\"Next_Tmin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932eb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f01efb",
   "metadata": {},
   "source": [
    "as we have already done the data cleaning and preprocessing before so lets move to training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data scaling using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_scaled=scaler.fit_transform(x)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dba40a",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.25,random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd19e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajusted r2 score\n",
    "lr.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f422e22",
   "metadata": {},
   "source": [
    "lets check how well fits the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1aceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc5403",
   "metadata": {},
   "source": [
    "here we have handled the problem of overfitting and underfitting by checking the training and testing score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734f1ec",
   "metadata": {},
   "source": [
    "# cross validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911758e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy=lr.score(x_train,y_train)\n",
    "test_accuracy=lr.score(x_test,y_test)\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df5212",
   "metadata": {},
   "source": [
    "# lets plot and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254e366",
   "metadata": {},
   "source": [
    "its shows the good fit of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c6b4c",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9db19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters={'alpha':[.001,.001,.01,.1,1,10],'random_state':list(range(0,10))}\n",
    "ls=Lasso()\n",
    "clf=GridSearchCV(ls,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=Lasso(alpha=1,random_state=0)\n",
    "ls.fit(x_train,y_train)\n",
    "ls_score_training=ls.score(x_train,y_train)\n",
    "pred_ls=ls.predict(x_test)\n",
    "ls_score_training*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lss=r2_score(y_test,pred_ls)\n",
    "lss*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6019dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "cv_mean=cv_score.mean()\n",
    "cv_mean*100\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad761700",
   "metadata": {},
   "source": [
    "# Ensemble Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1addbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "parameters={'criterion':['mse','mae'],'max_features':[\"auto\",\"sqrt\",\"log2\"]}\n",
    "rf=RandomForestRegressor()\n",
    "clf=GridSearchCV(rf,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(criterion=\"mse\",max_features=\"auto\")\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_train,y_train)\n",
    "pred_decision=rf.predict(x_test)\n",
    "\n",
    "rfs=r2_score(y_test,pred_decision)\n",
    "print('R2_score :',rfs*100)\n",
    "\n",
    "rfscore=cross_val_score(rf,x,y,cv=5)\n",
    "rfc=rfscore.mean()\n",
    "print('Cross_val_score :',rfc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3aef8",
   "metadata": {},
   "source": [
    "we are getting good r2_score and cross_val_score which shows that model is performing well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072cb00e",
   "metadata": {},
   "source": [
    "# save model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Temperature_Forecast2.pkl'\n",
    "pickle.dump(rf,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d488a",
   "metadata": {},
   "source": [
    "# prediction using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open('Temperature_Forecast2.pkl','rb'))\n",
    "result=loaded_model.score(x_test,y_test)\n",
    "print(result*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edcaa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion=pd.DataFrame([loaded_model.predict(x_test)[:],pred_decision[:]],index=[\"Orignal\",\"Predicted\"])\n",
    "conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
